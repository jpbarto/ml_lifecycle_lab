{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Host and infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding training job, when complete, will produce a model export into the configured `S3 output path`.  We will now use that output to create a model which can then be hosted by SageMaker.  The creation of a model can be done programmatically using the code below, alternatively you can create a model manually via the SageMaker web console.\n",
    "\n",
    "First we will need to create a 'Model' in SageMaker which is a logical construct that associates the export in S3 with a specific algorithm container.  Once the model has been created you will then create an Endpoint Configuration which tells SageMaker the resources needed to run the model in production.  Finally you will deploy an Endpoint using the Endpoint Configuration to create a hosted, secure, RESTful ML service.\n",
    "\n",
    "## Create a model from training output\n",
    "\n",
    "### From the console:\n",
    "From the SageMaker web console `Inference` -> `Model`.  Then click `Create model`.\n",
    "\n",
    "Give your model a name such as 'xgboost-forecast-model' and then set the `Location of inference code image` to a value such as `644912444149.dkr.ecr.eu-west-2.amazonaws.com/xgboost:latest`.  \n",
    "\n",
    "Next set the `Location of model artifacts` to a value such as `s3://jasbarto-forecast-lab/output/xgboost-forecast-stock-01-copy-2-copy-12-17-copy-12-17/output/model.tar.gz`\n",
    "\n",
    "Click `Create model`.\n",
    "\n",
    "You can always reference the training job details to obtain values for the fields above such as S3 model export location.\n",
    "\n",
    "### Using the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_JOB_NAME = ' < TRAINING JOB NAME FROM LAB 04 > '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker import get_execution_role\n",
    "from time import sleep, strftime, gmtime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost')\n",
    "\n",
    "client = boto3.client ('sagemaker')\n",
    "\n",
    "job_name = YOUR_JOB_NAME\n",
    "model_name=job_name + '-model'\n",
    "print(model_name)\n",
    "\n",
    "info = client.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_data)\n",
    "\n",
    "primary_container = {\n",
    "    'Image': container,\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "\n",
    "create_model_response = client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint configuration\n",
    "\n",
    "SageMaker hosts your model as an endpoint.  This endpoint must be configured with which models you would like it to host.  To create an endpoint configuration you can use the code below to create one programmatically or create one manually via the web console.\n",
    "\n",
    "From the SageMaker web console click `Endpoint configurations` under `Inference`.  Click `Create endpoint configuration`.\n",
    "\n",
    "Give your endpoint configuration a name such as 'xgboost-model-endpoint-config' and under 'Production variants' click `Add model`.  Select the model you created in the previous step and click `Create endpoint configuration`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = 'DEMO-XGBoostEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m4.4xlarge',\n",
    "        'InitialVariantWeight':1,\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy endpoint\n",
    "\n",
    "Finally deploy the configured endpoint so that it can be invoked as a secure, RESTful endpoint.  To deploy the endpoint you can use the code below or create a deployment manually via the web console.\n",
    "\n",
    "From the SageMaker web console click `Endpoints` under `Inference`.  Click `Create endpoint`.  Give your endpoint a name such as `xgboost-endpoint` and select the endpoint configuration created in the previous step.  Click `Deploy endpoint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "endpoint_name = 'DEMO-XGBoostEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Creating':\n",
    "    sleep(60)\n",
    "    resp = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp['EndpointArn'])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the endpoint\n",
    "\n",
    "Once the SageMaker endpoint has been deployed your trained model is running and ready to perform inference.  Let's test it now using the Boto3 client.  We will use some of the training data produced earlier.  Alternatively you could create a yet unseen data set from a recent month and transform it using the logic in lab 4.  Once transformed you can send this data to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_file = !ls data/train/train | head -n1\n",
    "csv_data_file = \"data/train/train/{}\".format (csv_data_file[0])\n",
    "print (\"Will invoke endpoint using data from {}\".format (csv_data_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n1 {csv_data_file} > /tmp/test_data_single.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import json\n",
    "from itertools import islice\n",
    "import math\n",
    "import struct\n",
    "import boto3\n",
    "\n",
    "sm_client = boto3.client ('runtime.sagemaker')\n",
    "\n",
    "def predict (features):\n",
    "    response = sm_client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='text/csv', \n",
    "                                   Body=features)\n",
    "    result = response['Body'].read()\n",
    "    return result\n",
    "\n",
    "file_name = '/tmp/test_data_single.csv' #customize to your test file\n",
    "\n",
    "with open(file_name, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "label, features = payload.split (',', 1)\n",
    "print (\"Label: {}\\nPrediction: {}\".format (label, predict (features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the convenience function defined above iterate over the contents of the `test_data.csv` file and record the prediction for each observation.  The first number of every observation is the label for that observation, store the label, along with the prediction to then compare them as a measure of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_labels = []\n",
    "test_predictions = []\n",
    "\n",
    "file_name = '/tmp/test_data_multiple.csv'\n",
    "!head -n500 {csv_data_file} > {file_name}\n",
    "\n",
    "with open (file_name, 'r') as f:\n",
    "    for line in f:\n",
    "        payload = line.strip ()\n",
    "        label, features = payload.split (',', 1)\n",
    "        pred = predict (features)\n",
    "        test_labels.append (float(label))\n",
    "        test_predictions.append (float(pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `mean_squared_error` function from the `sklearn.metrics` module.  Use the `mean_squared_error` function to calculate the accuracy of the model against the labels and predictions collected in the previous step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame ()\n",
    "data['True_Y'] = test_labels\n",
    "data['Pred_Y'] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "data.plot.line(figsize=(25,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print (\"RMSE: {}\".format (mean_squared_error(test_labels, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (test_labels[:10])\n",
    "print (test_predictions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Complete\n",
    "\n",
    "That completes this lab.  You should have trained and created a hosted SageMaker model using the XGBoost algorithm for predicting stock movements using time series analysis.  Now think about how you could improve the accuracy of the model.  What are some of the things you could do to perhaps the data, the algorithm, or the algorithm parameters, to further enhance the performance of your trained model?\n",
    "\n",
    "### Note: Remove created resources\n",
    "As part of this lab you will have created an S3 bucket, a SageMaker notebook server, and at least one training job, model, and endpoint.  Please be sure to create each of these to avoid incurring any further charges to your AWS account."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
